{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VzzPw7rEZ-OX"
   },
   "source": [
    "# Coursework 2: Generative Models\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "Please submit on CATe a zip file named *CW2.zip* containing the following:\n",
    "1. A version of this notebook containing your answers. Write your answers in the cells below each question.\n",
    "2. Your trained models as *VAE_model.pth, DCGAN_model_D.pth, DCGAN_model_G.pth*\n",
    "\n",
    "#### Working environment:\n",
    "\n",
    "Similarly to the previous coursework, we recommend that you use Google Colaboratory in order to train the required networks.\n",
    "\n",
    "**The deadline for submission is 19:00, Thursday 27th February, 2020**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oqY55OLpxDm"
   },
   "source": [
    "### Setting up working environment\n",
    "\n",
    "For this coursework you, will need to train a large network, therefore we recommend you work with Google Colaboratory, which provides free GPU time. You will need a Google account to do so.\n",
    "\n",
    "Please log in to your account and go to the following page: https://colab.research.google.com. Then upload this notebook.\n",
    "\n",
    "For GPU support, go to \"Edit\" -> \"Notebook Settings\", and select \"Hardware accelerator\" as \"GPU\".\n",
    "\n",
    "You will need to install pytorch by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJg7ozC_q3HF"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VVTDWQ66rTVL"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "For this coursework, you are asked to implement two commonly used generative models:\n",
    "1. A **Variational Autoencoder (VAE)**\n",
    "2. A **Deep Convolutional Generative Adversarial Network (DCGAN)**\n",
    "\n",
    "For the first part you will the MNIST dataset https://en.wikipedia.org/wiki/MNIST_database and for the second the CIFAR-10 (https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "## Part 1 (50 points)\n",
    "1. For the first part, you are asked to implement a Variational Autoencoder on the MNIST dataset. You will be assesed by the following:\n",
    "    - **loss function and proper explanations**. You will have to choose the right loss function by properly modelling the probability distributions involved. There are more than one accepted approaches. \n",
    "    - **reconstruction error**. You will need to achieve a low enough error in order to reconstruct the images of the dataset with relatively high fidelity. You will have to provide us with your best model's training and test loss curves (both the total loss and each individual term), a few reconstructed images and a few sampled images from the latent space of the VAE in the respective cells.\n",
    "    - **qualitative results**. You have to provide us with certain qualitative results that are usually used to assess the quality of the learned representations (more info below)\n",
    "\n",
    " \n",
    "## Part 2 (50 points)\n",
    "2. For the DCGAN, The success of your models will be tested as follows:\n",
    "    - **By the model's training error**. You will need to achieve relatively balanced errors for the generator and the discriminator of your model in order to sample realistic images from the generator. You will have to provide us with your best model's training losses curves, a discussion on how you concluded to the chosen architecture, and visualizations of generated samples in the respective cells. Your results do not have to be perfect, however a good discussion on the choice of architecture will be valued.\n",
    "    - **By avoiding mode collapse**. A common problem of training GANs is that they end up generating only a few different samples (if not only one), rather than learning the whole distribution of the training data. This problem is referred to as mode collapse. You will need to make a discussion on whether you noticed mode collapse or not during your experimentation and if yes, how you addressed it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPMdk0kWJtLv"
   },
   "source": [
    "# Part 1 - Variational Autoencoder\n",
    "\n",
    "## Part 1.1 (25 points)\n",
    "**Your Task:**\n",
    "\n",
    "a. Implement the VAE architecture. You are free to choose either Multilayer Perceptrons (MLPs) or Convolutional Layers\n",
    "\n",
    "You will need to define:\n",
    "*  The hyperparameters\n",
    "* The constructor\n",
    "* encode\n",
    "* reparametrize\n",
    "* decode\n",
    "* forward\n",
    "\n",
    "b. Design an appropriate loss function. There are multiple accepted solutions. Explain your design choices based on the assumptions you make regarding the distribution of your data.\n",
    "\n",
    "* Hint: this refers to the log likelihood as mentioned in the tutorial. Make sure these assumptions reflect on the values of your input data, i.e. depending on your choice you might need to do a simple preprocessing step.\n",
    "\n",
    "* You are encouraged to experiment with the weighting coefficient $\\beta$ and observe how it affects your training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ym5l5RmmJtLw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show(img):\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cpu()\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "# device selection\n",
    "GPU = True\n",
    "device_idx = 0\n",
    "if GPU:\n",
    "    device = torch.device(\"cuda:\" + str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "# We set a random seed to ensure that your results are reproducible.\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(0)\n",
    "\n",
    "if not os.path.exists('./CW_VAE/MNIST'):\n",
    "    os.makedirs('./CW_VAE/MNIST')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqT7sdGzJtLy"
   },
   "source": [
    "## Hyper-parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZVPM6pgqJtLz"
   },
   "outputs": [],
   "source": [
    "# *CODE FOR PART 1.1 IN THIS CELL*\n",
    "\n",
    "### Choose the number of epochs, the learning rate and the batch size\n",
    "num_epochs = \n",
    "learning_rate  =  \n",
    "batch_size = \n",
    "### Choose a value for the size of the latent space\n",
    "latent_dim = \n",
    "\n",
    "###\n",
    "\n",
    "# Define here the any extra hyperparameters you used.\n",
    "\n",
    "###\n",
    "\n",
    "# Modify this line if you need to do any input transformations (optional).\n",
    "transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Modify the denorm function in case you need to do any output transformation when visualizing your images\n",
    "\n",
    "denorm = lambda x:x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iN5aL7sdJtL2"
   },
   "source": [
    "## Data loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VOKdAZa2JtL3"
   },
   "outputs": [],
   "source": [
    "train_dat = datasets.MNIST(\n",
    "    \"data/\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dat = datasets.MNIST(\"data/\", train=False, transform=transform)\n",
    "\n",
    "loader_train = DataLoader(train_dat, batch_size, shuffle=True)\n",
    "loader_test = DataLoader(test_dat, batch_size, shuffle=False)\n",
    "\n",
    "sample_inputs, _ = next(iter(loader_test))\n",
    "fixed_input = sample_inputs[:32, :, :, :]\n",
    "\n",
    "save_image(fixed_input, './CW_VAE/MNIST/image_original.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LiQDXD24JtL7"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDlll3BUJtL8"
   },
   "outputs": [],
   "source": [
    "# *CODE FOR PART 1.1a IN THIS CELL*\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        #######################################################################\n",
    "        #                       ** START OF YOUR CODE **\n",
    "        #######################################################################\n",
    "\n",
    "        #######################################################################\n",
    "        #                       ** END OF YOUR CODE **\n",
    "        ####################################################################### \n",
    "        \n",
    "        \n",
    "    def encode(self, x):\n",
    "        #######################################################################\n",
    "        #                       ** START OF YOUR CODE **\n",
    "        #######################################################################\n",
    "\n",
    "        #######################################################################\n",
    "        #                       ** END OF YOUR CODE **\n",
    "        ####################################################################### \n",
    "    \n",
    "    def reparametrize(self, mu, logvar):\n",
    "        #######################################################################\n",
    "        #                       ** START OF YOUR CODE **\n",
    "        #######################################################################\n",
    "\n",
    "        #######################################################################\n",
    "        #                       ** END OF YOUR CODE **\n",
    "        ####################################################################### \n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        #######################################################################\n",
    "        #                       ** START OF YOUR CODE **\n",
    "        #######################################################################\n",
    "\n",
    "        #######################################################################\n",
    "        #                       ** END OF YOUR CODE **\n",
    "        ####################################################################### \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #######################################################################\n",
    "        #                       ** START OF YOUR CODE **\n",
    "        #######################################################################\n",
    "\n",
    "        #######################################################################\n",
    "        #                       ** END OF YOUR CODE **\n",
    "        ####################################################################### \n",
    "\n",
    "    \n",
    "model = VAE().to(device)\n",
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))\n",
    "print(model)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeSX6RZhJtMB"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6CeeS9CJtMC"
   },
   "outputs": [],
   "source": [
    "# *CODE FOR PART 1.1b IN THIS CELL*\n",
    "\n",
    "def loss_function_VAE():\n",
    "        #######################################################################\n",
    "        #                       ** START OF YOUR CODE **\n",
    "        #######################################################################\n",
    "\n",
    "        #######################################################################\n",
    "        #                       ** END OF YOUR CODE **\n",
    "        ####################################################################### \n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):     \n",
    "        #######################################################################\n",
    "        #                       ** START OF YOUR CODE **\n",
    "        #######################################################################\n",
    "\n",
    "        #######################################################################\n",
    "        #                       ** END OF YOUR CODE **\n",
    "        ####################################################################### \n",
    "\n",
    "\n",
    "# save the model \n",
    "torch.save(model.state_dict(), './CW_VAE/MNIST/VAE_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vF6B26_oJtMF"
   },
   "source": [
    "### Your explanations about the loss function here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ez5nlMi1JtMF"
   },
   "source": [
    "## Part 1.2 (10 points)\n",
    "\n",
    "a. Plot your loss curves (6 in total, 3 for the training set and 3 for the test set): total loss, reconstruction log likelihood loss, KL loss (x-axis: epochs, y-axis: loss). \n",
    "\n",
    "b. Provide a brief analysis of your loss curves. What do you observe in the behaviour of the log-likelihood loss and the KL loss (increasing/decreasing)? Can you intuitively explain if this behaviour is desirable? Have you observed posterior collapse during traing (i.e. when the KL is too small during the early stages of training)? If yes, how did you mitigate it? How did this phenomenon reflect on your output samples? \n",
    "\n",
    "c. Visualize a subset of the images of the test set and their reconstructions as well as a few generated samples. Most of the code for this part is provided. You only need to call the forward pass of the model for the given inputs (might vary depending on your implementation) .Please deliver the notebook including the outputs of the cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AADYspqtJtMG"
   },
   "outputs": [],
   "source": [
    "# *CODE FOR PART 1.2a IN THIS CELL*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vy4KKp2UJtMJ"
   },
   "source": [
    "### Your answer to 1.2b here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wu9CWtqoJtMK"
   },
   "outputs": [],
   "source": [
    "# *CODE FOR PART 1.2c IN THIS CELL*\n",
    "\n",
    "# load the model\n",
    "model.load_state_dict(torch.load('./CW_VAE/MNIST/VAE_model.pth'))\n",
    "sample_inputs, _ = next(iter(loader_test))\n",
    "fixed_input = sample_inputs[0:32, :, :, :]\n",
    "\n",
    "# visualize the original images of the last batch of the test set\n",
    "img = make_grid(denorm(fixed_input), nrow=8, padding=2, normalize=False,\n",
    "                range=None, scale_each=False, pad_value=0)\n",
    "plt.figure()\n",
    "show(img)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # visualize the reconstructed images of the last batch of test set\n",
    "    \n",
    "    #######################################################################\n",
    "    #                       ** START OF YOUR CODE **\n",
    "    #######################################################################\n",
    "    recon_batch = \n",
    "    #######################################################################\n",
    "    #                       ** END OF YOUR CODE **\n",
    "    ####################################################################### \n",
    "    \n",
    "    recon_batch = recon_batch.cpu()\n",
    "    recon_batch = make_grid(denorm(recon_batch), nrow=8, padding=2, normalize=False,\n",
    "                            range=None, scale_each=False, pad_value=0)\n",
    "    plt.figure()\n",
    "    show(recon_batch)\n",
    "    \n",
    "model.eval()\n",
    "n_samples = 256\n",
    "z = torch.randn(n_samples,latent_dim).to(device)\n",
    "with torch.no_grad():\n",
    "    #######################################################################\n",
    "    #                       ** START OF YOUR CODE **\n",
    "    #######################################################################\n",
    "    samples = \n",
    "    #######################################################################\n",
    "    #                       ** END OF YOUR CODE **\n",
    "    ####################################################################### \n",
    "    \n",
    "    samples = samples.cpu()\n",
    "    samples = make_grid(denorm(samples), nrow=16, padding=2, normalize=False,\n",
    "                            range=None, scale_each=False, pad_value=0)\n",
    "    plt.figure(figsize = (8,8))\n",
    "    show(samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyRsJ2DTJtMN"
   },
   "source": [
    "## Part 1.3 (15 points)\n",
    "\n",
    "### Qualitative analysis of the learned representations\n",
    "\n",
    "In this question you are asked to qualitatively assess the representations that your model has learned. In particular:\n",
    "\n",
    "a. Extract the latent representations of the test set and visualize them using T-SNE (https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding, https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) or PCA. What do you observe? Discuss the structure of the visualized representations. Please use different colours for each digit class.\n",
    "\n",
    "b. Perform a linear interpolation in the latent space of the autoencoder by choosing any two digits from the test set. What do you observe regarding the transition from on digit to the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VP8RLfqNJtMO"
   },
   "outputs": [],
   "source": [
    "# *CODE FOR PART 1.3a IN THIS CELL*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRP52xcsJtMQ"
   },
   "source": [
    "### Your answer to 1.3a here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "atIcunIrJtMR"
   },
   "outputs": [],
   "source": [
    "# *CODE FOR PART 1.3b IN THIS CELL*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2F5t3RdqJtMV"
   },
   "source": [
    "### Your answer to 1.3b here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EG68ntJ2qfIC"
   },
   "source": [
    "## Part 2 - Deep Convolutional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9r4ZEOcZ-Pb"
   },
   "source": [
    "In this task, your main objective is to train a DCGAN (https://arxiv.org/abs/1511.06434) on the CIFAR-10 dataset. You should experiment with different architectures, tricks for stability in training (such as using different activation functions, batch normalization, different values for the hyper-parameters, etc.). In the end, you should provide us with: \n",
    "\n",
    "- your best trained model (which we will be able to run), \n",
    "- some generations for the fixed latent vectors $\\mathbf{z}\\sim \\mathcal{N}\\left(\\mathbf{0}, \\mathbf{I}\\right)$ we have provided you with (train for a number of epochs and make sure there is no mode collapse), \n",
    "- plots with the losses for the discriminator $D$ and the generator $G$ as the training progresses and explain whether your produced plots are theoretically sensible and why this is (or not) the case. \n",
    "- a discussion on whether you noticed any mode collapse, where this behaviour may be attributed to, and explain what you did in order to cope with mode collapse. \n",
    "\n",
    "_Clarification: You should not be worrying too much about getting an \"optimal\" performance on your trained GAN. We want you to demonstrate to us that you experimented with different types of DCGAN variations, report what difficulties transpired throughout the training process, etc. In other words, if we see that you provided us with a running implementation, that you detail different experimentations that you did before providing us with your best one, and that you have grapsed the concepts, you can still get full marks. The attached model does not have to be perfect._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDwWdd0zZ-Pc"
   },
   "source": [
    "### Part 2.1 (30 points)\n",
    "**Your Task**: \n",
    "\n",
    "a. Implement the DCGAN architecture. Fill in the missing parts in the cells below in order to complete the Generator and Discriminator classes. You will need to define:\n",
    "\n",
    "- The hyperparameters\n",
    "- The constructors\n",
    "- `decode`\n",
    "- `discriminator`\n",
    "\n",
    "b. visualize images sampled from your best model's generator.\n",
    "\n",
    "c. Discuss the experimentations which led to your final architecture. You can plot losses or generated results by other architectures that you tested to back your arguments (but this is not necessary to get full marks).\n",
    "\n",
    "For b. the code is already given. Make sure that the version of the notebook you deliver includes these results. \n",
    "\n",
    "Recomendations for experimentation:\n",
    "- use the architecture that you implemented for the Autoencoder of Part 1 (encoder as discriminator, decoder as generator).\n",
    "- use the architecture desribed in the DCGAN paper (https://arxiv.org/abs/1511.06434).\n",
    "\n",
    "Some general reccomendations:\n",
    "- add several convolutional layers (3-4).\n",
    "- accelerate training with batch normalization after every convolutional layer.\n",
    "- use the appropriate activation functions. \n",
    "- Generator module: the upsampling can be done with various methods, such as nearest neighbor upsampling (`torch.nn.Upsample`) or transposed convolutions(`torch.nn.ConvTranspose2d`). \n",
    "- Discriminator module: Experiment with batch normalization (`torch.nn.BatchNorm2d`) and leaky relu (`torch.nn.LeakyReLu`) units after each convolutional layer.\n",
    "\n",
    "Try to follow the common practices for CNNs (e.g small receptive fields, max pooling, RELU activations), in order to narrow down your possible choices.\n",
    "\n",
    "The number of epochs that will be needed in order to train the network will vary depending on your choices. As an advice, we recommend that while experimenting you should allow around 20 epochs and if the loss doesn't sufficiently drop, restart the training with a more powerful architecture. You don't need to train the network to an extreme if you don't have the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uFEt7wGXP_aE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def denorm(x, channels=None, w=None ,h=None, resize = False):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    if resize:\n",
    "        if channels is None or w is None or h is None:\n",
    "            print('Number of channels, width and height must be provided for resize.')\n",
    "        x = x.view(x.size(0), channels, w, h)\n",
    "    return x\n",
    "\n",
    "def show(img):\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cpu()\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "# device selection\n",
    "GPU = True\n",
    "device_idx = 0\n",
    "if GPU:\n",
    "    device = torch.device(\"cuda:\" + str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "# We set a random seed to ensure that your results are reproducible.\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(0)\n",
    "\n",
    "if not os.path.exists('./CW_DCGAN'):\n",
    "    os.makedirs('./CW_DCGAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = None  # change that\n",
    "NUM_TRAIN = 49000\n",
    "\n",
    "transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "data_dir = './datasets'\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(data_dir, train=True, download=True,\n",
    "                             transform=transform)\n",
    "cifar10_val = datasets.CIFAR10(data_dir, train=True, download=True,\n",
    "                           transform=transform)\n",
    "cifar10_test = datasets.CIFAR10(data_dir, train=False, download=True, \n",
    "                            transform=transform)\n",
    "\n",
    "loader_train = DataLoader(cifar10_train, batch_size=batch_size, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "loader_val = DataLoader(cifar10_val, batch_size=batch_size, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "loader_test = DataLoader(cifar10_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XSkveP0mZ-Pd"
   },
   "source": [
    "### Hyper-parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FBoxMTihZ-Pd"
   },
   "outputs": [],
   "source": [
    "# *CODE FOR PART 2.1 IN THIS CELL*\n",
    "\n",
    "### Choose the number of epochs, the learning rate\n",
    "#   and the size of the Generator's input noise vetor.\n",
    "num_epochs = None\n",
    "learning_rate  = None\n",
    "latent_vector_size = None\n",
    "###\n",
    "\n",
    "# Define here other hyperparameters that you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATTUAhCDZ-Pg"
   },
   "outputs": [],
   "source": [
    "# *CODE FOR PART 2.1 IN THIS CELL*\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        #######################################################################\n",
    "        #                       ** START OF YOUR CODE **\n",
    "        #######################################################################\n",
    "\n",
    "        #######################################################################\n",
    "        #                       ** END OF YOUR CODE **\n",
    "        ####################################################################### \n",
    "\n",
    "    def decode(self, z):\n",
    "        #######################################################################\n",
    "        #                       ** START OF YOUR CODE **\n",
    "        #######################################################################\n",
    "\n",
    "        #######################################################################\n",
    "        #                       ** END OF YOUR CODE **\n",
    "        ####################################################################### \n",
    "        return x\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.decode(z)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        #######################################################################\n",
    "        #                       ** START OF YOUR CODE **\n",
    "        #######################################################################\n",
    "\n",
    "        #######################################################################\n",
    "        #                       ** END OF YOUR CODE **\n",
    "        ####################################################################### \n",
    "        \n",
    "    def discriminator(self, x):\n",
    "        #######################################################################\n",
    "        #                       ** START OF YOUR CODE **\n",
    "        #######################################################################\n",
    "\n",
    "        #######################################################################\n",
    "        #                       ** END OF YOUR CODE **\n",
    "        ####################################################################### \n",
    "        \n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.discriminator(x)\n",
    "        return outs.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o8YDyYf8Z-Pi"
   },
   "source": [
    "### Initialize Model and print number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xh3NpfD_Z-Pj"
   },
   "source": [
    "You can use method `weights_init` to initialize the weights of the Generator and Discriminator networks. Otherwise, implement your own initialization, or do not use at all. You will not be penalized for not using initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JAVpgpmUZ-Pk"
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ew-OdvNJZ-Pm"
   },
   "outputs": [],
   "source": [
    "use_weights_init = True\n",
    "\n",
    "model_G = Generator().to(device)\n",
    "if use_weights_init:\n",
    "    model_G.apply(weights_init)\n",
    "params_G = sum(p.numel() for p in model_G.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters in Generator is: {}\".format(params_G))\n",
    "print(model_G)\n",
    "print('\\n')\n",
    "\n",
    "model_D = Discriminator().to(device)\n",
    "if use_weights_init:\n",
    "    model_D.apply(weights_init)\n",
    "params_D = sum(p.numel() for p in model_D.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters in Discriminator is: {}\".format(params_D))\n",
    "print(model_D)\n",
    "print('\\n')\n",
    "\n",
    "print(\"Total number of parameters is: {}\".format(params_G + params_D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00wgs1VNZ-Pp"
   },
   "source": [
    "### Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gPlxaL_cZ-Pq"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss(reduction='mean')\n",
    "def loss_function(out, label):\n",
    "    loss = criterion(out, label)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GrgmhlSXZ-Ps"
   },
   "source": [
    "### Choose and initialize optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFM8iI24Z-Pt"
   },
   "outputs": [],
   "source": [
    "# setup optimizer\n",
    "# You are free to add a scheduler or change the optimizer if you want. We chose one for you for simplicity.\n",
    "beta1 = 0.5\n",
    "optimizerD = torch.optim.Adam(model_D.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
    "optimizerG = torch.optim.Adam(model_G.parameters(), lr=learning_rate, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qZ311RPlZ-Pv"
   },
   "source": [
    "### Define fixed input vectors to monitor training and mode collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGB_9A1UZ-Pw"
   },
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(batch_size, latent_vector_size, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gD9S_3yZZ-Py"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w5vD--X6Z-Pz"
   },
   "outputs": [],
   "source": [
    "train_losses_G = []\n",
    "train_losses_D = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_D = 0\n",
    "    train_loss_G = 0\n",
    "    for i, data in enumerate(loader_train, 0):\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################device\n",
    "        # train with real\n",
    "        model_D.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "\n",
    "        output = model_D(real_cpu)\n",
    "        errD_real = loss_function(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, latent_vector_size, 1, 1, device=device)\n",
    "        fake = model_G(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = model_D(fake.detach())\n",
    "        errD_fake = loss_function(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        train_loss_D += errD.item()\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        model_G.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = model_D(fake)\n",
    "        errG = loss_function(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        train_loss_G += errG.item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, num_epochs, i, len(loader_train),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "    if epoch == 0:\n",
    "        save_image(denorm(real_cpu.cpu()).float(), './CW_DCGAN/real_samples.png')\n",
    "    \n",
    "    fake = model_G(fixed_noise)\n",
    "    save_image(denorm(fake.cpu()).float(), './CW_DCGAN/fake_samples_epoch_%03d.png' % epoch)\n",
    "    train_losses_D.append(train_loss_D / len(loader_train))\n",
    "    train_losses_G.append(train_loss_G / len(loader_train))\n",
    "            \n",
    "# save losses and models\n",
    "torch.save(model_G.state_dict(), './CW_DCGAN/DCGAN_model_G.pth')\n",
    "torch.save(model_D.state_dict(), './CW_DCGAN/DCGAN_model_D.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-iJCcRg2Z-P2"
   },
   "outputs": [],
   "source": [
    "# DISCUSS THE SELECTION OF THE ARCHITECTURE IN THIS CELL*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5IQIKTdPZ-P5"
   },
   "source": [
    "### Generator samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pR5lxyqgZ-P6"
   },
   "outputs": [],
   "source": [
    "it = iter(loader_test)\n",
    "sample_inputs, _ = next(it)\n",
    "fixed_input = sample_inputs[0:32, :, :, :]\n",
    "\n",
    "# visualize the original images of the last batch of the test set\n",
    "img = make_grid(denorm(fixed_input), nrow=4, padding=2, normalize=False,\n",
    "                range=None, scale_each=False, pad_value=0)\n",
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VIHi0HrJZ-P8"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "model_G.load_state_dict(torch.load('./CW_DCGAN/DCGAN_model_G.pth'))\n",
    "input_noise = torch.randn(batch_size, latent_vector_size, 1, 1, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # visualize the generated images\n",
    "    generated = model_G(input_noise).cpu()\n",
    "    generated = make_grid(denorm(generated)[:32], nrow=8, padding=2, normalize=False, \n",
    "                        range=None, scale_each=False, pad_value=0)\n",
    "    show(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DC6ndLP5Z-P-"
   },
   "source": [
    "### Part 2.2 (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zz6oy7ixZ-P_"
   },
   "source": [
    "### Train losses curves\n",
    "**Your task:**\n",
    "\n",
    "\n",
    "Plot the losses curves for the discriminator $D$ and the generator $G$ as the training progresses and explain whether the produced curves are theoretically sensible and why this is (or not) the case (x-axis: epochs, y-axis: loss).\n",
    "\n",
    "The code for generating the plot is already given. Make sure that the version of the notebook you deliver includes these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxrUDHfBZ-QA"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(range(0, np.array(train_losses_D).shape[0])), np.array(train_losses_D), label='loss_D')\n",
    "plt.plot(list(range(0, np.array(train_losses_G).shape[0])), np.array(train_losses_G), label='loss_G')\n",
    "plt.legend()\n",
    "plt.title('Train Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ls_WtVLPZ-QC"
   },
   "outputs": [],
   "source": [
    "# ANSWER FOR PART 2.2 IN THIS CELL*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_WLkdSNZ-QE"
   },
   "source": [
    "### Part 2.3 (10 points) \n",
    "**Your task:** \n",
    "\n",
    "Based on the images created by your generator using the `fixed_noise` vector during training, provide a discussion on whether you noticed any mode collapse, where this behaviour may be attributed to, and explain what you did in order to cope with mode collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "reXM_U0iZ-QF"
   },
   "outputs": [],
   "source": [
    "# ANSWER FOR PART 2.3 IN THIS CELL*\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "460cw2_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
